{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanremo 2023\n",
    "\n",
    "Sanremo, FantaSanremo, and more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tweepy\n",
    "tweepy.__version__\n",
    "\n",
    "import re\n",
    "import string\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import time\n",
    "import json\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert the keys here\n",
    "consumer_key = 'x' \n",
    "consumer_secret = 'x'\n",
    "access_token = 'x'\n",
    "access_token_secret = 'x'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is creating an OAuthHandler instance. We pass our consumer key and access token which we defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we pass the OAuthHandler instance into the API method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweets that contain a specific hashtag/keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags = \"#sanremo2023\"\n",
    "\n",
    "list_tweets = []\n",
    "\n",
    "try:\n",
    "  for tweet in tweepy.Cursor(api.search_tweets, q=hashtags, count=100, lang='it').items(100000):\n",
    "    print('entering')\n",
    "    full_text = api.get_status(tweet.id, tweet_mode='extended')._json['full_text']\n",
    "    print(tweet.id)\n",
    "    list_tweets.append([tweet.created_at, tweet.id, full_text, tweet.favorite_count, tweet.retweet_count, tweet.user.screen_name,\n",
    "                      tweet.user.location, tweet.retweeted, json.dumps(tweet.entities['user_mentions']), json.dumps(tweet.entities['hashtags'])])\n",
    "except tweepy.TweepyException:\n",
    "    pass\n",
    "\n",
    "# items is the maximum number of tweets to download.\n",
    "# count is the number of tweets to return per page, up to a maximum of 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(list_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn list_tweet into a DataFrame changing column names\n",
    "tweets = pd.DataFrame(list_tweets, columns=['date','id','text','like','n_rt','author','location','retweeted','user_mentions','hastags'])\n",
    "tweets.to_csv('../data/raw/sanremo2023_api.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tweets.shape)\n",
    "print(tweets.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweets that contains specific hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags = '(\"#fantasanremo\" OR \"#fantasanremo2023\")'\n",
    "\n",
    "list_tweets = []\n",
    "\n",
    "try:\n",
    "  for tweet in tweepy.Cursor(api.search_tweets, q=hashtags, count=100, lang='it').items(100000):\n",
    "    print('entering')\n",
    "    full_text = api.get_status(tweet.id, tweet_mode='extended')._json['full_text']\n",
    "    print(tweet.id)\n",
    "    list_tweets.append([tweet.created_at, tweet.id, full_text, tweet.favorite_count, tweet.retweet_count, tweet.user.screen_name,\n",
    "                      tweet.user.location, tweet.retweeted, json.dumps(tweet.entities['user_mentions']), json.dumps(tweet.entities['hashtags'])])\n",
    "except tweepy.TweepyException:\n",
    "    pass\n",
    "\n",
    "# items is the maximum number of tweets to download.\n",
    "# count is the number of tweets to return per page, up to a maximum of 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(list_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn list_tweet into a DataFrame changing column names\n",
    "tweets = pd.DataFrame(list_tweets, columns=['date','id','text','like','n_rt','author','location','retweeted','user_mentions','hastags'])\n",
    "tweets.to_csv('../data/raw/fantasanremo2023_api.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tweets.shape)\n",
    "print(tweets.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative method by scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tweepy\n",
    "tweepy.__version__\n",
    "\n",
    "import re\n",
    "import string\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import time\n",
    "import json\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking User Input \n",
    "\n",
    "To scrape tweets, you can provide many filters such as the username or start date or end date etc. We will be taking the following user inputs which will then be used in Snscrape. \n",
    "\n",
    "- Text: The query to be matched. (Optional)\n",
    "- Username: Specific username from twitter account. (Required)\n",
    "- Since: Start Date in this format yyyy-mm-dd. (Optional)\n",
    "- Until: End Date in this format yyyy-mm-dd. (Optional)\n",
    "- Count: Max number of tweets to retrieve. (Required)\n",
    "- Retweet: Include or Exclude Retweets. (Required)\n",
    "- Replies: Include or Exclude Replies. (Required)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which field can we Scrape? \n",
    "\n",
    "Here is the list of fields which we can scrape using Snscrape Library. \n",
    "\n",
    "- url: str\n",
    "- date: datetime.datetime \n",
    "- rawContent: str\n",
    "- renderedContent: str\n",
    "- id: int\n",
    "- user: 'User'\n",
    "- replyCount: int\n",
    "- retweetCount: int\n",
    "- likeCount: int\n",
    "- quoteCount: int\n",
    "- conversationId: int\n",
    "- lang: str\n",
    "- source: str\n",
    "- sourceUrl: typing.Optional[str] = None\n",
    "- sourceLabel: typing.Optional[str] = None\n",
    "- links: typing.Optional[typing.List['TextLink']] = None\n",
    "- media: typing.Optional[typing.List['Medium']] = None\n",
    "- retweetedTweet: typing.Optional['Tweet'] = None\n",
    "- quotedTweet: typing.Optional['Tweet'] = None\n",
    "- inReplyToTweetId: typing.Optional[int] = None\n",
    "- inReplyToUser: typing.Optional['User'] = None\n",
    "- mentionedUsers: typing.Optional[typing.List['User']] = None\n",
    "- coordinates: typing.Optional['Coordinates'] = None\n",
    "- place: typing.Optional['Place'] = None\n",
    "- hashtags: typing.Optional[typing.List[str]] = None\n",
    "- cashtags: typing.Optional[typing.List[str]] = None\n",
    "- card: typing.Optional['Card'] = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper = sntwitter.TwitterSearchScraper('#sanremo2023')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "for i, tweet in enumerate(scraper.get_items()):\n",
    "    data = [\n",
    "        tweet.date,\n",
    "        tweet.id,\n",
    "        tweet.rawContent,\n",
    "        tweet.user.username,\n",
    "        tweet.likeCount,\n",
    "        tweet.retweetCount\n",
    "    ]\n",
    "    tweets.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.DataFrame(\n",
    "    tweets,\n",
    "    columns=[\n",
    "        'date',\n",
    "        'id',\n",
    "        'content',\n",
    "        'username',\n",
    "        'like_count',\n",
    "        'retweet_count'\n",
    "    ]\n",
    ")\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.to_csv('../data/raw/sanremo2023_scraping.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper = sntwitter.TwitterSearchScraper('#fantasanremo OR #fantasanremo2023 since:2022-12-25 until:2023-02-13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "for i, tweet in enumerate(scraper.get_items()):\n",
    "    data = [\n",
    "        tweet.date,\n",
    "        tweet.id,\n",
    "        tweet.rawContent,\n",
    "        tweet.user.username,\n",
    "        tweet.likeCount,\n",
    "        tweet.retweetCount\n",
    "    ]\n",
    "    tweets.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>username</th>\n",
       "      <th>like_count</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-02-12 23:52:01+00:00</td>\n",
       "      <td>1624919283410010112</td>\n",
       "      <td>@giovannitruppi ha interceduto per me presso l...</td>\n",
       "      <td>mg_polemos</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-02-12 23:43:39+00:00</td>\n",
       "      <td>1624917176950878208</td>\n",
       "      <td>Mamma ho vinto il fantasanremo. #fantasanremo</td>\n",
       "      <td>Albos182</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-02-12 23:36:19+00:00</td>\n",
       "      <td>1624915331981484032</td>\n",
       "      <td>Non male come primo #fantasanremo , so proud o...</td>\n",
       "      <td>millenialhorror</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-02-12 23:35:46+00:00</td>\n",
       "      <td>1624915193250693121</td>\n",
       "      <td>@mengonimarco io ti amo, confidavo in te #fant...</td>\n",
       "      <td>camispadaroo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-02-12 23:30:16+00:00</td>\n",
       "      <td>1624913809243619329</td>\n",
       "      <td>Per essere il mio primo #fantasanremo direi no...</td>\n",
       "      <td>Ale89KP</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date                   id  \\\n",
       "0 2023-02-12 23:52:01+00:00  1624919283410010112   \n",
       "1 2023-02-12 23:43:39+00:00  1624917176950878208   \n",
       "2 2023-02-12 23:36:19+00:00  1624915331981484032   \n",
       "3 2023-02-12 23:35:46+00:00  1624915193250693121   \n",
       "4 2023-02-12 23:30:16+00:00  1624913809243619329   \n",
       "\n",
       "                                             content         username  \\\n",
       "0  @giovannitruppi ha interceduto per me presso l...       mg_polemos   \n",
       "1      Mamma ho vinto il fantasanremo. #fantasanremo         Albos182   \n",
       "2  Non male come primo #fantasanremo , so proud o...  millenialhorror   \n",
       "3  @mengonimarco io ti amo, confidavo in te #fant...     camispadaroo   \n",
       "4  Per essere il mio primo #fantasanremo direi no...          Ale89KP   \n",
       "\n",
       "   like_count  retweet_count  \n",
       "0           0              0  \n",
       "1           0              0  \n",
       "2           1              0  \n",
       "3           0              0  \n",
       "4           3              0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df = pd.DataFrame(\n",
    "    tweets,\n",
    "    columns=[\n",
    "        'date',\n",
    "        'id',\n",
    "        'content',\n",
    "        'username',\n",
    "        'like_count',\n",
    "        'retweet_count'\n",
    "    ]\n",
    ")\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.to_csv('../data/raw/fantasanremo2023_scraping.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting variables to be used below\n",
    "maxTweets = 1000000\n",
    "\n",
    "# Creating list to append tweet data to\n",
    "tweets_list2 = []\n",
    "\n",
    "# Using TwitterSearchScraper to scrape data and append tweets to list\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('#fantasanremo OR #fantasanremo2023 since:2022-12-25 until:2023-02-13').get_items()):\n",
    "    if i>maxTweets:\n",
    "        break\n",
    "    tweets_list2.append([tweet.date, tweet.id, tweet.content, tweet.username])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "social",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "378175c2c6ec7d4fc364b1674a9631fcafdf0526712f6e898c5a9c4fd1a3d1ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
